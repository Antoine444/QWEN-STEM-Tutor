{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict, Features, Value, load_dataset\n",
    "from huggingface_hub import HfApi, HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f258991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Builds + pushes students' preference dataset to 🤗 Hub (`derko83/m3_dpo`).\n",
    "\"\"\"\n",
    "RAW_FILE = Path(\"m1_preference_data.json\")  # preference pairs of students\n",
    "HF_REPO = \"derko83/m3_dpo\"                    \n",
    "SEED = 42\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\", \"\")                                \n",
    "\n",
    "\n",
    "def _normalise(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = \"\\n\".join(ln.strip() for ln in text.splitlines())\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def build_prompt(item: dict) -> str:\n",
    "    stem = _normalise(item.get(\"question_body\", \"\"))\n",
    "    if item.get(\"question_type\", \"\").lower() == \"mcq\":\n",
    "        options = item.get(\"question_options\") or []\n",
    "        if options:\n",
    "            opt_block = \"\\n\".join(f\"{i}. {opt}\" for i, opt in enumerate(options))\n",
    "            return f\"{stem}\\n\\nOptions:\\n{opt_block}\"\n",
    "    return stem\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    with RAW_FILE.open(encoding=\"utf-8\") as f:\n",
    "        raw_items: list[dict] = json.load(f)\n",
    "\n",
    "    pairs: list[dict[str, str]] = []\n",
    "\n",
    "    for item in raw_items:\n",
    "        prompt = build_prompt(item)\n",
    "        if not prompt:\n",
    "            continue\n",
    "\n",
    "        for pref in item.get(\"preferences\") or []:\n",
    "            ans_a = _normalise(pref.get(\"A\", \"\"))\n",
    "            ans_b = _normalise(pref.get(\"B\", \"\"))\n",
    "            overall = _normalise(pref.get(\"ranking_criteria\", {}).get(\"overall\", \"\")).upper()\n",
    "\n",
    "            if overall not in {\"A\", \"B\"} or not ans_a or not ans_b or ans_a == ans_b:\n",
    "                continue\n",
    "\n",
    "            chosen, rejected = (ans_a, ans_b) if overall == \"A\" else (ans_b, ans_a)\n",
    "\n",
    "            pairs.append(\n",
    "                {\n",
    "                    \"prompt\":   prompt,\n",
    "                    \"chosen\":   chosen,\n",
    "                    \"rejected\": rejected,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    unique_triples = {(p[\"prompt\"], p[\"chosen\"], p[\"rejected\"]) for p in pairs}\n",
    "    pairs = [dict(zip((\"prompt\", \"chosen\", \"rejected\"), triplet)) for triplet in unique_triples]\n",
    "\n",
    "    if not pairs:\n",
    "        raise RuntimeError(\"No valid preference pairs produced – aborting.\")\n",
    "\n",
    "\n",
    "    features = Features(\n",
    "        {\n",
    "            \"prompt\":   Value(\"string\"),\n",
    "            \"chosen\":   Value(\"string\"),\n",
    "            \"rejected\": Value(\"string\"),\n",
    "        }\n",
    "    )\n",
    "    full_ds = Dataset.from_list(pairs, features=features).shuffle(seed=SEED)\n",
    "    dsd: DatasetDict = DatasetDict({\"train\": full_ds})  \n",
    "\n",
    "\n",
    "    print(f\"📝  Final size: {len(dsd['train'])} train\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b65bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_HelpSteer3():\n",
    "    \"\"\"\"\n",
    "    Preprocess the HelpSteer3 dataset for DPO training.\n",
    "    This function filters the dataset for STEM and code domains, processes the responses based on overall preference,\n",
    "    and formats the context into a prompt string.\"\"\"\n",
    "    dataset = load_dataset(\"nvidia/HelpSteer3\", split=\"train\")\n",
    "    stem_data = dataset.filter(lambda x: x[\"domain\"] == \"stem\" or x[\"domain\"] == \"code\")\n",
    "    processed = []\n",
    "    for idx, item in tqdm(enumerate(stem_data), total=len(stem_data), desc=\"Processing HelpSteer3\"):\n",
    "        if item[\"overall_preference\"] >= 0:\n",
    "            chosen = item[\"response1\"]\n",
    "            rejected = item[\"response2\"]\n",
    "        else:\n",
    "            chosen = item[\"response2\"]\n",
    "            rejected = item[\"response1\"]\n",
    "            prompt = \"\"\n",
    "        \n",
    "        # Format the context into a prompt string\n",
    "        if \"context\" in item and isinstance(item[\"context\"], list):\n",
    "            prompt = \"\"\n",
    "            for turn in item[\"context\"]:\n",
    "                role = turn.get(\"role\", \"\")\n",
    "                content = turn.get(\"content\", \"\")\n",
    "                prompt += f\"{role}: {content}\\n\\n\"\n",
    "        \n",
    "        processed.append({\n",
    "            \"id\": f\"dpo_dataset_helpsteer3_{idx}\",\n",
    "            \"dataset\": \"helpsteer3\",\n",
    "            \"prompt\": prompt,\n",
    "            \"chosen\": chosen,\n",
    "            \"rejected\": rejected\n",
    "        })\n",
    "    return processed    \n",
    "\n",
    "def pre_processs_10K_step_dpo():\n",
    "    \"\"\"\"\n",
    "    Preprocess the 10K-step-dpo dataset for DPO training.\n",
    "    This function loads the dataset, processes each item, and formats it into a structured format.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"xinlai/Math-Step-DPO-10K\", split=\"train\")\n",
    "    processed = []\n",
    "    for idx, item in tqdm(enumerate(dataset), total=len(dataset), desc=\"Processing 10K-step-dpo\"):\n",
    "        processed.append({\n",
    "            \"id\": f\"dpo_dataset_10K_step_dpo_{idx}\",\n",
    "            \"dataset\": \"10K-step-dpo\",\n",
    "            \"prompt\": item[\"prompt\"],\n",
    "            \"chosen\": item[\"full_chosen\"],\n",
    "            \"rejected\": item[\"full_rejected\"]\n",
    "        })\n",
    "    return processed\n",
    "\n",
    "def pre_process_students_pairs():\n",
    "    \"\"\"\"\n",
    "    Preprocess the students' preference pairs dataset for DPO training.\n",
    "    This function loads the dataset, processes each item, and formats it into a structured format.\n",
    "    \"\"\"\n",
    "    ds_reloaded = load_dataset(\"derko83/m3_dpo\", split=\"train\")\n",
    "    processed = []\n",
    "    for idx, item in tqdm(enumerate(ds_reloaded), total=len(ds_reloaded), desc=\"Processing pair students\"):\n",
    "        processed.append({\n",
    "            \"id\": f\"pref_pairs_students_{idx}\",\n",
    "            \"dataset\": \"students_preference_pairs\",\n",
    "            \"prompt\": item[\"prompt\"],\n",
    "            \"chosen\": item[\"chosen\"],\n",
    "            \"rejected\": item[\"rejected\"]\n",
    "        })\n",
    "    return processed\n",
    "\n",
    "def pre_process_distilled_math():\n",
    "    \"\"\"\"\n",
    "    Preprocess the Distilabel Math Preference DPO dataset.\n",
    "    This function loads the dataset, processes each item, and formats it into a structured format.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"argilla/distilabel-math-preference-dpo\", split=\"train\")\n",
    "    processed = []\n",
    "    for idx, item in tqdm(enumerate(dataset), total=len(dataset), desc=\"Processing 10K-step-dpo\"):\n",
    "        processed.append({\n",
    "            \"id\": f\"distilabel-math-preference-dpo{idx}\",\n",
    "            \"dataset\": \"distilabel-math-preference-dpo\",\n",
    "            \"prompt\": item[\"instruction\"],\n",
    "            \"chosen\": item[\"chosen_response\"],\n",
    "            \"rejected\": item[\"rejected_response\"]\n",
    "        })\n",
    "    return processed\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = []\n",
    "    data.extend(pre_process_students_pairs())\n",
    "    data.extend(pre_process_HelpSteer3())\n",
    "    data.extend(pre_processs_10K_step_dpo())\n",
    "    data.extend(pre_process_distilled_math())\n",
    "    with open(\"full_m3_dpo_dataset.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(\"✅ full_m3_dpo_dataset.json has been saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_JSON = \"full_m3_dpo_dataset.json\"\n",
    "HF_REPO = \"derko83/full_m3_dpo\"\n",
    "SEED = 42\n",
    "VALID_FRAC = 0.05\n",
    "\n",
    "def main():\n",
    "    # Load data from JSON\n",
    "    with open(INPUT_JSON, encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    features = Features({\n",
    "        \"id\":       Value(\"string\"),\n",
    "        \"dataset\":  Value(\"string\"),\n",
    "        \"prompt\":   Value(\"string\"),\n",
    "        \"chosen\":   Value(\"string\"),\n",
    "        \"rejected\": Value(\"string\"),\n",
    "    })\n",
    "\n",
    "    dataset = Dataset.from_list(data, features=features).shuffle(seed=SEED)\n",
    "\n",
    "    # Train/Validation split\n",
    "    dsd = dataset.train_test_split(test_size=VALID_FRAC, seed=SEED)\n",
    "    dsd[\"validation\"] = dsd.pop(\"test\")  # rename for consistency\n",
    "\n",
    "    print(f\"📝 Final size: {len(dsd['train'])} train • {len(dsd['validation'])} validation\")\n",
    "\n",
    "    # Push to Hugging Face Hub\n",
    "    dsd.push_to_hub(HF_REPO, private=True, token=HF_TOKEN)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_reward_bench():\n",
    "    \"\"\"\n",
    "    Create the test set of the dataset.\n",
    "    This function filters the reward-bench dataset for specific STEM subsets and processes each item into a structured format.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"allenai/reward-bench\", split = \"raw\")\n",
    "    dataset = dataset.filter(lambda ex: ex[\"subset\"] == \"hep-cpp\" or ex[\"subset\"] == \"hep-go\" or ex[\"subset\"] == \"hep-java\" or ex[\"subset\"] == \"hep-js\" or ex[\"subset\"] == \"hep-python\" or ex[\"subset\"] == \"hep-rust\" or ex[\"subset\"] == \"math-prm\" )\n",
    "    processed = []\n",
    "    for idx, item in tqdm(enumerate(dataset), total=len(dataset), desc=\"Processing reward bench\"):\n",
    "        processed.append({\n",
    "            \"id\": f\"reward-bench{idx}\",\n",
    "            \"dataset\": \"reward-bench\",\n",
    "            \"prompt\": item[\"prompt\"],\n",
    "            \"chosen\": item[\"chosen\"],\n",
    "            \"rejected\": item[\"rejected\"]\n",
    "        })\n",
    "    return processed\n",
    "\n",
    "def main():\n",
    "    data = []\n",
    "    data.extend(pre_process_reward_bench())\n",
    "    with open(\"reward_bench_processed.json\", \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(\"✅ reward_bench_processed.json has been saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed JSON file\n",
    "with open(\"reward_bench_processed.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a Hugging Face Dataset from the list\n",
    "ds = Dataset.from_list(data)\n",
    "\n",
    "# Push the dataset to your existing Hugging Face repo\n",
    "ds.push_to_hub(repo_id=HF_REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final version of my dataset for M3 we train + validation + test set and the finalized dataset is pushed at address \"derko83/MNLP_M3_dpo_dataset\"\n",
    "\n",
    "token = HfFolder.get_token()\n",
    "api = HfApi()\n",
    "\n",
    "full = load_dataset(\"derko83/full_m3_dpo\")\n",
    "train_ds = full[\"train\"]\n",
    "val_ds   = full[\"validation\"]\n",
    "\n",
    "test_ds = load_dataset(\"derko83/reward_bench_processed\", split=\"train\")\n",
    "\n",
    "new_ds = DatasetDict({\n",
    "    \"train\":      train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\":       test_ds\n",
    "})\n",
    "\n",
    "repo_id = \"derko83/MNLP_M3_dpo_dataset\"\n",
    "new_ds.push_to_hub(repo_id, token=token)\n",
    "\n",
    "print(f\"✅ Successfully pushed dataset to https://huggingface.co/{repo_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
